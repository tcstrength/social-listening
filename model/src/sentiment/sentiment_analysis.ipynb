{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "/home/jovyan/work\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%cd /home/jovyan/work\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/home/jovyan/work/src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle as pkl\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sentiment import tweet_utils\n",
    "from sentiment import tweet_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "unk_token = \"__<UNK>__\"\n",
    "tweets = tweet_loader.load_all_tweets()\n",
    "counter = tweet_utils.build_counter([x[0] for x in tweets])\n",
    "vocab = tweet_utils.build_vocab(counter, 10, [x[0] for x in tweets], unk_token=unk_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Model hyper parameters__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"model/sentiment.keras\"\n",
    "emb_dim = 128\n",
    "num_epochs = 5\n",
    "batch_size = 64\n",
    "maxlen = 128\n",
    "lstm_units = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tweets, test_tweets = train_test_split(tweets, test_size=0.1)\n",
    "def tweets_to_X_y(vocab: dict, tweets: list, unk_token: str, maxlen: int) -> tuple:\n",
    "    X = [x[0] for x in tweets]\n",
    "    X = [tweet_utils.tweet_to_tensor(vocab, x[0], unk_token, maxlen) for x in tweets]\n",
    "    y = [x[1] for x in tweets]\n",
    "    return np.array(X).reshape(-1, maxlen), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = tweets_to_X_y(vocab, train_tweets, unk_token, maxlen)\n",
    "X_test, y_test = tweets_to_X_y(vocab, test_tweets, unk_token, maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "443/443 [==============================] - 55s 123ms/step - loss: 0.3839 - accuracy: 0.8356\n",
      "Epoch 2/5\n",
      "443/443 [==============================] - 53s 120ms/step - loss: 0.3176 - accuracy: 0.8721\n",
      "Epoch 3/5\n",
      "443/443 [==============================] - 52s 118ms/step - loss: 0.2972 - accuracy: 0.8783\n",
      "Epoch 4/5\n",
      "443/443 [==============================] - 57s 128ms/step - loss: 0.2793 - accuracy: 0.8870\n",
      "Epoch 5/5\n",
      "443/443 [==============================] - 56s 126ms/step - loss: 0.2640 - accuracy: 0.8937\n",
      "99/99 [==============================] - 4s 31ms/step\n",
      "Accuracy on test dataset: [0.87158296]\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(input_dim=len(vocab), output_dim=emb_dim, input_length=maxlen))\n",
    "model.add(tf.keras.layers.LSTM(lstm_units))\n",
    "model.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=num_epochs, batch_size=batch_size)\n",
    "model.save(model_path)\n",
    "\n",
    "num_correct = 0\n",
    "for ind, score in enumerate(model.predict(X_test)):\n",
    "    num_correct += y_test[ind] == (score >= 0.5)\n",
    "print(f\"Accuracy on test dataset: {num_correct / len(y_test)}\")\n",
    "\n",
    "context = {\n",
    "    \"model.emb_dim\": 128,\n",
    "    \"model.num_epochs\": 5,\n",
    "    \"model.batch_size\": 64,\n",
    "    \"model.maxlen\": 128,\n",
    "    \"model.lstm_units\": 100,\n",
    "    \"model.sentiment_path\": model_path,\n",
    "    \"data.unk\": unk_token,\n",
    "    \"data.vocab\": vocab,\n",
    "    \"data.counter\": counter\n",
    "}\n",
    "pkl.dump(open(\"model/context.pkl\"), context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = {\n",
    "    \"model.emb_dim\": 128,\n",
    "    \"model.num_epochs\": 5,\n",
    "    \"model.batch_size\": 64,\n",
    "    \"model.maxlen\": 128,\n",
    "    \"model.lstm_units\": 100,\n",
    "    \"model.sentiment_path\": model_path,\n",
    "    \"model.unk_token\": unk_token,\n",
    "    \"data.vocab\": vocab,\n",
    "    \"data.counter\": counter\n",
    "}\n",
    "pkl.dump(context, open(\"model/context.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentiment import sentiment_analyzer\n",
    "analyzer = sentiment_analyzer.SentimentAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.95593405"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer.analyze(\"Chào bạn, mình rất thích bạn\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
